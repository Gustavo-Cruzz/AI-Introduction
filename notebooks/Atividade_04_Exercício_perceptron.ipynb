{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Atividade 04 - Exercício perceptron ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Capacitação Vialab # Atividade 4\n",
        "\n",
        "## Criar um perceptron simples e usar para classificação\n",
        "### Data de atualização: 08/02/2022\n",
        "\n",
        "# Objetivo: Entender o funcionamento basico de uma rede neural resolvendo problemas de classificação usando perceptron simples"
      ],
      "metadata": {
        "id": "Zq3l31lp0V7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercício de classificação \n",
        "\n",
        "Para realizar este exercício vamos usar os dados do dataset iris para treinar um perceptron. O objetivo é modelar um perceptron utilizando os conceitos de input, pesos, bias, backpropagation e ativação. Plotar grafico com a previsão ao final, Lembrando de plotar a reta de regressão linear, e validar.   \n"
      ],
      "metadata": {
        "id": "zo-WqMiQvecc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# O dataset consiste em 50 amostras para ralizar a classificação de 2 tipos diferentes de flores iris. \n",
        "#### Para simplificar o problemas, reduziremos o escopo para dois tipos de plantas e duas entradas, o dataset completo será usado no exercicio de CNN."
      ],
      "metadata": {
        "id": "tPzAUfAx2rFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# carregando e Transformando os dados\n",
        "from  sklearn import  datasets\n",
        "import collections\n",
        "import numpy as np\n",
        "# Carregando o dataset iris\n",
        "iris = datasets.load_iris()\n",
        "# Armazenando os dados para a previsão em X \n",
        "X = iris.data\n",
        "# Armazenando as respostas (ou target) em y\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "v_322C6O2vrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)\n",
        "# como o dataset esta organizado, vamos remover a ultima classe (2)\n",
        "lastpos = np.where(y == 2)[0][0] -1 \n",
        "\n",
        "y = y[0:lastpos]\n",
        "X = X[0:lastpos]"
      ],
      "metadata": {
        "id": "5m4OK2ol21r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Redução de dimensionalidade utilizando PCA (APROFUNDAREMOS NISSO EM OUTRO MOMENTO)\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "n_components = 2\n",
        "\n",
        "pca = PCA(n_components=n_components)\n",
        "\n",
        "X = pca.fit_transform(X)"
      ],
      "metadata": {
        "id": "ynLxY9ao74MN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y"
      ],
      "metadata": {
        "id": "KGqxk8qn8cc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(X[:,0],X[:,1], 'o', color=\"black\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fherprk08jOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Desenvolvimento:"
      ],
      "metadata": {
        "id": "pDkmulvL-8Dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Esqueleto perceptron como base\n",
        "class Perceptron():\n",
        "    #w = [Bias,W1,W2]\n",
        "    def __init__(self, w, threshold,variation):\n",
        "     self.w = w\n",
        "     self.threshold = threshold # usado para calcular a classificação\n",
        "     self.variation = variation # O quanto o erro vai impactar no atualização dos pesos\n",
        "\n",
        "    def Treinar(self,Data): #Data = v[x,y,resultado]\n",
        "        print(\"Data - \" + str(Data))\n",
        "        return self.Calcular(Data)\n",
        "        \n",
        "    def Calcular(self,vet):\n",
        "       \n",
        "        print(\"Weights - \" + str(self.w))\n",
        "        #Calculo da operação do perceptron\n",
        "        \n",
        "        # gerar classificação apartir de  limiar/função de ativação\n",
        "        if func >= self.threshold:\n",
        "            func = 1\n",
        "        else:\n",
        "            func = 0\n",
        "\n",
        "        # calcular o erro\n",
        "       \n",
        "       \n",
        "       #realizar back propagation\n",
        "        self.Corrigir(vet,erro)    \n",
        "        return erro #se nao funcioanr\n",
        "\n",
        "    def  Corrigir(self,vet,corr):# calculo do back propagation\n",
        "        # self.w[0] += \n",
        "        # self.w[1] += \n",
        "        # self.w[2] += "
      ],
      "metadata": {
        "id": "IUCy8QPR_jNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pYUHryM8_icX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Referências \n",
        "\n",
        "https://medium.com/sanju-notes/introduction-to-perceptron-78a386f4bd73\n",
        "\n",
        "https://www.deeplearningbook.com.br/o-perceptron-parte-1/"
      ],
      "metadata": {
        "id": "7_jAdnOdP5m1"
      }
    }
  ]
}